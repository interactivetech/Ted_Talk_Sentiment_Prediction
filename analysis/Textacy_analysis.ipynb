{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import textacy\n",
    "import json\n",
    "from tqdm import tqdm \n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_list_of_dicts(arr):\n",
    "    dict_ratings = {}\n",
    "    for a in arr:\n",
    "        if a[\"id\"] not in dict_ratings:\n",
    "            dict_ratings[a[\"id\"]]=a\n",
    "            \n",
    "    return dict_ratings\n",
    "\n",
    "\n",
    "def getTEDRating(string):\n",
    "    arr = json.loads(string.replace(\"'\",'\\\"'))\n",
    "    d = combine_list_of_dicts(arr) \n",
    "    return sorted(d.items(), key= lambda x:x[1][\"count\"],reverse=True)[0][1]['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"data/transcripts.csv\")\n",
    "df2 = pd.read_csv(\"data/ted_main.csv\")\n",
    "merged = df1.merge(df2, on=\"url\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [getTEDRating(x) for x in merged['ratings'].tolist()]\n",
    "merged['label'] = labels\n",
    "merged.to_csv(\"data/Merged_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Textacy analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2467/2467 [34:34<00:00,  1.19it/s]\n"
     ]
    }
   ],
   "source": [
    "corpus=[]\n",
    "docs = merged['transcript'].tolist()\n",
    "for doc in tqdm(docs):\n",
    "    corpus.append(textacy.Doc(content=doc,\n",
    "                              lang='en'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_corpus = textacy.corpus.Corpus('en', docs=corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2467, 343476, 5999227)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_corpus.n_docs, new_corpus.n_sents, new_corpus.n_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_docs = (doc.to_terms_list(ngrams=1, \n",
    "                                    named_entities=True, \n",
    "                                    as_strings=True) \n",
    "                  for doc in new_corpus)\n",
    "vectorizer = textacy.Vectorizer(apply_idf=True, norm='l2',\n",
    "                                idf_type='smooth',\n",
    "                                min_df=3, max_df=0.95)\n",
    "doc_term_matrix = vectorizer.fit_transform(tokenized_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0 : so   people   go   think   know   thing   say   have   but   want\n",
      "topic 1 : ♫   ♫ ♫   song   sing   da   music   video   heh   oh   la\n",
      "topic 2 : cell   dna   stem   gene   genome   tissue   drug   organ   disease   virus\n",
      "topic 3 : country   africa   government   world   china   percent   people   economy   economic   global\n",
      "topic 4 : cancer   patient   tumor   drug   doctor   disease   health   treatment   breast   blood\n",
      "topic 5 :    woman   ebola   autistic   drug   satellite   antibiotic   people   brazil   pete\n",
      "topic 6 : planet   earth   water   ocean   universe   mars   star   galaxy   energy   sea\n",
      "topic 7 : brain   neuron   so   memory   cortex   disorder   control   body   region   signal\n",
      "topic 8 : city   building   design   space   architecture   build   car   neighborhood   street   urban\n",
      "topic 9 : robot   robotic   so   machine   ai   build   leg   human   locomotion   intelligence\n"
     ]
    }
   ],
   "source": [
    "model = textacy.TopicModel('nmf', n_topics=10)\n",
    "model.fit(doc_term_matrix)\n",
    "doc_topic_matrix = model.transform(doc_term_matrix)\n",
    "doc_topic_matrix.shape\n",
    "\n",
    "for topic_idx, top_terms in model.top_topic_terms(vectorizer.id_to_term, top_n=10):\n",
    "    print('topic', topic_idx, ':', '   '.join(top_terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
